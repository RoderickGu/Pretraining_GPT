{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pytorch_transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trainListFile.json\", \"r\") as f:\n",
    "    train_list = f.readlines()\n",
    "    train_list = [item.strip() for item in train_list]\n",
    "\n",
    "with open(\"valListFile.json\", \"r\") as f:\n",
    "    val_list = f.readlines()\n",
    "    val_list = [item.strip() for item in val_list]\n",
    "\n",
    "with open(\"testListFile.json\", \"r\") as f:\n",
    "    test_list = f.readlines()\n",
    "    test_list = [item.strip() for item in test_list]\n",
    "    \n",
    "with open(\"data_for_sequicity_new_ptr.json\", \"r\") as f:\n",
    "    all_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_list(file_list):\n",
    "    data = []\n",
    "    for file in train_list:\n",
    "        try:\n",
    "            data.append(all_data[file.lower()[:-5]])\n",
    "        except:\n",
    "            print(file.lower()[:-5], \"not found\")\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmul2245 not found\n",
      "pmul4776 not found\n",
      "pmul3872 not found\n",
      "pmul4859 not found\n",
      "pmul2245 not found\n",
      "pmul4776 not found\n",
      "pmul3872 not found\n",
      "pmul4859 not found\n",
      "pmul2245 not found\n",
      "pmul4776 not found\n",
      "pmul3872 not found\n",
      "pmul4859 not found\n"
     ]
    }
   ],
   "source": [
    "train_data = retrieve_list(train_list)\n",
    "val_data = retrieve_list(val_list)\n",
    "test_data = retrieve_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_data.json\", \"w\") as f:\n",
    "    json.dump(train_data, f, indent=4)\n",
    "    \n",
    "with open(\"val_data.json\", \"w\") as f:\n",
    "    json.dump(val_data, f, indent=4)\n",
    "    \n",
    "with open(\"test_data.json\", \"w\") as f:\n",
    "    json.dump(test_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'i am looking for an italian restaurant located in the centre of cambridge .',\n",
       " 'user_delex': 'i am looking for an [value_food] restaurant located in the [value_area] of cambridge .',\n",
       " 'resp': 'there are [value_choice] of them . what price range do you prefer ?',\n",
       " 'pointer': '0,0,0,1,0,0',\n",
       " 'match': '9',\n",
       " 'constraint': '[restaurant] food italian area centre',\n",
       " 'cons_delex': '[restaurant] food area',\n",
       " 'sys_act': '[restaurant] [inform] choice [request] price',\n",
       " 'turn_num': 0,\n",
       " 'turn_domain': '[restaurant]'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[800]['log'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
